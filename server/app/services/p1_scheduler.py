"""
P1+ Enhanced Scheduler
å¢å¼ºçš„æ•°æ®é‡‡é›†è°ƒåº¦å™¨

é›†æˆäº†æ–°çš„æ•°æ®é‡‡é›†å™¨:
- OneTokenæŠ•èµ„ç»„åˆé‡‡é›†å™¨
- Ceffué’±åŒ…èµ„äº§é‡‡é›†å™¨
- æ±‡ç‡æ•°æ®é‡‡é›†å™¨
"""

import asyncio
import logging
from datetime import datetime, timedelta
from typing import Optional, Dict, List
from sqlalchemy.orm import Session

from server.app.database import SessionLocal
from server.app.services.data_collector import collector_registry
from server.app.services.onetoken_collector import OneTokenCollector
from server.app.services.ceffu_collector import CeffuCollector
from server.app.services.exchange_rate_collector import ExchangeRateCollector
from server.app.services.onetoken_client import OneTokenClient
from server.app.services.ceffu_client import CeffuClient
from server.app.config import settings

logger = logging.getLogger(__name__)


class DataCollectionScheduler:
    """
    P1+ æ•°æ®é‡‡é›†è°ƒåº¦å™¨
    
    åŠŸèƒ½:
    1. æ¯å°æ—¶å®šæ—¶é‡‡é›†æ•°æ®
    2. ç®¡ç†å¤šä¸ªé‡‡é›†å™¨
    3. é”™è¯¯å¤„ç†ä¸é‡è¯•
    4. é‡‡é›†ç»“æœç»Ÿè®¡
    """
    
    def __init__(self):
        self.running = False
        self.tasks: List[asyncio.Task] = []
        self.collectors_initialized = False
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_runs': 0,
            'successful_runs': 0,
            'failed_runs': 0,
            'last_run_time': None,
            'last_run_success': None
        }
    
    async def initialize_collectors(self):
        """
        åˆå§‹åŒ–æ‰€æœ‰æ•°æ®é‡‡é›†å™¨
        
        åˆ›å»ºå¹¶æ³¨å†Œ:
        - OneTokené‡‡é›†å™¨
        - Ceffué‡‡é›†å™¨
        - æ±‡ç‡é‡‡é›†å™¨
        """
        if self.collectors_initialized:
            logger.warning("Collectors already initialized")
            return
        
        try:
            logger.info("Initializing data collectors...")
            
            # åˆå§‹åŒ–OneTokenå®¢æˆ·ç«¯å’Œé‡‡é›†å™¨
            onetoken_client = OneTokenClient(
                api_key=settings.onetoken_api_key,
                secret=settings.onetoken_secret
            )
            onetoken_collector = OneTokenCollector(onetoken_client)
            collector_registry.register(onetoken_collector)
            logger.info("âœ… OneToken collector registered")
            
            # åˆå§‹åŒ–Ceffuå®¢æˆ·ç«¯å’Œé‡‡é›†å™¨
            ceffu_client = CeffuClient(
                public_key=settings.ceffu_public_key,
                private_key=settings.ceffu_private_key
            )
            ceffu_collector = CeffuCollector(ceffu_client)
            collector_registry.register(ceffu_collector)
            logger.info("âœ… Ceffu collector registered")
            
            # åˆå§‹åŒ–æ±‡ç‡é‡‡é›†å™¨
            exchange_rate_collector = ExchangeRateCollector()
            collector_registry.register(exchange_rate_collector)
            logger.info("âœ… Exchange rate collector registered")
            
            self.collectors_initialized = True
            logger.info(f"All collectors initialized ({len(collector_registry.get_all())} total)")
            
        except Exception as e:
            logger.error(f"Failed to initialize collectors: {e}", exc_info=True)
            raise
    
    async def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        if self.running:
            logger.warning("Scheduler is already running")
            return
        
        # åˆå§‹åŒ–é‡‡é›†å™¨
        if not self.collectors_initialized:
            await self.initialize_collectors()
        
        self.running = True
        logger.info("ğŸš€ Starting P1+ data collection scheduler")
        
        # å¯åŠ¨æ¯å°æ—¶é‡‡é›†ä»»åŠ¡
        hourly_task = asyncio.create_task(self._schedule_hourly_collection())
        self.tasks.append(hourly_task)
        
        logger.info("âœ… P1+ scheduler started successfully")
    
    async def stop(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        if not self.running:
            return
        
        self.running = False
        logger.info("Stopping P1+ scheduler...")
        
        # å–æ¶ˆæ‰€æœ‰ä»»åŠ¡
        for task in self.tasks:
            task.cancel()
        
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        await asyncio.gather(*self.tasks, return_exceptions=True)
        self.tasks.clear()
        
        logger.info("âœ… P1+ scheduler stopped")
    
    async def _schedule_hourly_collection(self):
        """
        æ¯å°æ—¶æ•°æ®é‡‡é›†è°ƒåº¦
        
        åœ¨æ¯å°æ—¶çš„ç¬¬5åˆ†é’Ÿå¼€å§‹é‡‡é›† (ç»™APIä¸€äº›æ—¶é—´å‡†å¤‡æ•°æ®)
        """
        while self.running:
            try:
                # è®¡ç®—ä¸‹æ¬¡é‡‡é›†æ—¶é—´ (ä¸‹ä¸€ä¸ªå°æ—¶çš„ç¬¬5åˆ†é’Ÿ)
                now = datetime.now()
                next_hour = (now + timedelta(hours=1)).replace(minute=5, second=0, microsecond=0)
                
                # å¦‚æœå½“å‰å·²ç»è¿‡äº†ç¬¬5åˆ†é’Ÿï¼Œåˆ™ç­‰åˆ°ä¸‹ä¸ªå°æ—¶
                if now.minute >= 5:
                    next_hour = (now + timedelta(hours=1)).replace(minute=5, second=0, microsecond=0)
                else:
                    next_hour = now.replace(minute=5, second=0, microsecond=0)
                
                wait_seconds = (next_hour - now).total_seconds()
                
                logger.info(f"â° Next data collection in {wait_seconds:.0f} seconds ({next_hour.strftime('%Y-%m-%d %H:%M')})")
                
                await asyncio.sleep(wait_seconds)
                
                if self.running:
                    # é‡‡é›†æ—¶é—´æˆ³ä¸ºæ•´ç‚¹æ—¶é—´
                    collection_timestamp = next_hour.replace(minute=0)
                    await self._run_collection(collection_timestamp)
                    
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Error in hourly collection schedule: {e}", exc_info=True)
                await asyncio.sleep(300)  # ç­‰å¾…5åˆ†é’Ÿåé‡è¯•
    
    async def _run_collection(self, timestamp: datetime):
        """
        è¿è¡Œä¸€æ¬¡å®Œæ•´çš„æ•°æ®é‡‡é›†
        
        Steps:
        1. è¿è¡Œæ‰€æœ‰æ³¨å†Œçš„é‡‡é›†å™¨
        2. è®°å½•ç»“æœ
        3. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            timestamp: é‡‡é›†çš„æ—¶é—´æˆ³ (æ•´ç‚¹æ—¶é—´)
        """
        try:
            logger.info(f"=" * 80)
            logger.info(f"ğŸ“Š Starting data collection for {timestamp.strftime('%Y-%m-%d %H:%M')}")
            logger.info(f"=" * 80)
            
            self.stats['total_runs'] += 1
            self.stats['last_run_time'] = datetime.now()
            
            # è¿è¡Œæ‰€æœ‰é‡‡é›†å™¨
            results = await collector_registry.run_all(timestamp)
            
            # ç»Ÿè®¡ç»“æœ
            total_collectors = len(results)
            successful = sum(1 for success in results.values() if success)
            failed = total_collectors - successful
            
            # è®°å½•è¯¦ç»†ç»“æœ
            logger.info(f"\nğŸ“ˆ Collection Results:")
            logger.info(f"   Total collectors: {total_collectors}")
            logger.info(f"   âœ… Successful: {successful}")
            logger.info(f"   âŒ Failed: {failed}")
            
            for name, success in results.items():
                status = "âœ… SUCCESS" if success else "âŒ FAILED"
                logger.info(f"   - {name}: {status}")
            
            # æ›´æ–°ç»Ÿè®¡
            if failed == 0:
                self.stats['successful_runs'] += 1
                self.stats['last_run_success'] = True
                logger.info(f"\nğŸ‰ Data collection completed successfully!")
            else:
                self.stats['failed_runs'] += 1
                self.stats['last_run_success'] = False
                logger.warning(f"\nâš ï¸  Data collection completed with {failed} failures")
            
            logger.info(f"=" * 80)
            
        except Exception as e:
            logger.error(f"âŒ Error in data collection: {e}", exc_info=True)
            self.stats['failed_runs'] += 1
            self.stats['last_run_success'] = False
    
    async def run_manual_collection(self, timestamp: Optional[datetime] = None) -> Dict[str, bool]:
        """
        æ‰‹åŠ¨è§¦å‘ä¸€æ¬¡æ•°æ®é‡‡é›†
        
        Args:
            timestamp: é‡‡é›†æ—¶é—´æˆ³ (Noneè¡¨ç¤ºä½¿ç”¨å½“å‰æ—¶é—´)
            
        Returns:
            Dict[str, bool]: æ¯ä¸ªé‡‡é›†å™¨çš„ç»“æœ
        """
        if not self.collectors_initialized:
            await self.initialize_collectors()
        
        if timestamp is None:
            timestamp = datetime.now().replace(minute=0, second=0, microsecond=0)
        
        logger.info(f"ğŸ”§ Manual collection triggered for {timestamp.strftime('%Y-%m-%d %H:%M')}")
        
        await self._run_collection(timestamp)
        
        # è¿”å›æœ€è¿‘ä¸€æ¬¡è¿è¡Œçš„ç»“æœ
        return self.get_stats()
    
    def get_stats(self) -> Dict:
        """
        è·å–è°ƒåº¦å™¨ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict: ç»Ÿè®¡æ•°æ®
        """
        return {
            'total_runs': self.stats['total_runs'],
            'successful_runs': self.stats['successful_runs'],
            'failed_runs': self.stats['failed_runs'],
            'success_rate': (
                f"{(self.stats['successful_runs'] / self.stats['total_runs'] * 100):.1f}%"
                if self.stats['total_runs'] > 0 else "N/A"
            ),
            'last_run_time': (
                self.stats['last_run_time'].strftime('%Y-%m-%d %H:%M:%S')
                if self.stats['last_run_time'] else None
            ),
            'last_run_success': self.stats['last_run_success'],
            'collectors_count': len(collector_registry.get_all()),
            'running': self.running
        }


# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
p1_scheduler = DataCollectionScheduler()


async def start_p1_scheduler():
    """å¯åŠ¨P1+è°ƒåº¦å™¨"""
    await p1_scheduler.start()


async def stop_p1_scheduler():
    """åœæ­¢P1+è°ƒåº¦å™¨"""
    await p1_scheduler.stop()


async def trigger_manual_collection(timestamp: Optional[datetime] = None) -> Dict[str, bool]:
    """æ‰‹åŠ¨è§¦å‘æ•°æ®é‡‡é›†"""
    return await p1_scheduler.run_manual_collection(timestamp)


def get_scheduler_stats() -> Dict:
    """è·å–è°ƒåº¦å™¨ç»Ÿè®¡ä¿¡æ¯"""
    return p1_scheduler.get_stats()
